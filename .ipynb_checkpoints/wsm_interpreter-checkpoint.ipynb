{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76cb18-0204-4a83-a2bd-23747cdcedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet openai langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc5ab9-1f0b-4117-94f0-ffe27af8d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are receiving two lists of terms. The first list represents a topic in the field of food safety. The second list contains terms that might pose a risk to that topic.\n",
    "Based on your expert knowledge in the food safety domain your task is to infer what kind of food safety risk might occur based on the given data and produce a short statement to illustrate that risk.\n",
    "Example: Topic: ['cruzi', 'chagas', 'trypanosoma'];\n",
    "Risk: ['attalea'];\n",
    "Output: Deforestation effects on Attalea palms and their resident Rhodnius, vectors of Chagas disease, in eastern Amazonia.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93973cbe-4c74-4910-a305-293f8a981dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to generate text based on topic\n",
    "def infer_text2(label):\n",
    "    prompt = prompt_template + f\"\\ntopic: {topic}\\n\" + f\"\\nrisk: {risk}\\n\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in food safety.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        temperature=0.6,\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801b252-a5c8-42e0-b77d-ad72e8dda6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through each category and generate project descriptions\n",
    "for index, row in weak_signal_df.iterrows():\n",
    "    topic = row['core_topic']\n",
    "    risk = row['distant_terms']\n",
    "    text = infer_text2(topic)\n",
    "    results.append(text)\n",
    "\n",
    "\n",
    "weak_signal_df['odd_term_interpretaton'] = results"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
