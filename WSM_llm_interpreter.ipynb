{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2286aa9f-3a18-4d6b-bd53-dd6e679db707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-openai langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1710ba43-5849-46fd-8a3d-52cf77592711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa580c-f235-4f48-9324-2d3e52e5e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you prefer Gemini \n",
    "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your GOOGLE API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "920503d2-145c-4f45-a872-b57443a1e528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path : /home/jupyter/WSM/data/holifood_weak_signals.csv\n",
      "Output path: /home/jupyter/WSM/data/holifood_weak_singals_scored.csv\n",
      "LLM provider: openai\n",
      "Model name : gpt-5-mini\n",
      "Temperature: 0.4\n",
      "Has OPENAI_API_KEY: True\n",
      "Has GOOGLE_API_KEY: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & global config (single place for model + temperature)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATHS\n",
    "# ------------------------------------------------------------------\n",
    "IN_PATH = \"/home/jupyter/WSM/data/holifood_weak_signals.csv\"\n",
    "OUT_PATH = \"/home/jupyter/WSM/data/holifood_weak_singals_scored.csv\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LLM CONFIG – ONLY CHANGE IT HERE\n",
    "# ------------------------------------------------------------------\n",
    "LLM_PROVIDER = \"openai\"       # options: \"openai\", \"gemini\"\n",
    "MODEL_NAME = \"gpt-5-mini\"\n",
    "# MODEL_NAME = \"gemini-2.5-flash\"  # for Gemini\n",
    "MODEL_TEMPERATURE = 0.4\n",
    "\n",
    "print(\"Input path :\", IN_PATH)\n",
    "print(\"Output path:\", OUT_PATH)\n",
    "print(\"LLM provider:\", LLM_PROVIDER)\n",
    "print(\"Model name :\", MODEL_NAME)\n",
    "print(\"Temperature:\", MODEL_TEMPERATURE)\n",
    "\n",
    "print(\"Has OPENAI_API_KEY:\", \"OPENAI_API_KEY\" in os.environ)\n",
    "print(\"Has GOOGLE_API_KEY:\", \"GOOGLE_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78466ea-eb4a-48e7-956f-b771c9d61445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 2: Define the LLM prompt template (with topic label)\n",
    "\n",
    "LLM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are assisting in regulatory emerging risk assessment (food, feed, chemicals, environment).\n",
    "\n",
    "Each data point is a *topic* detected by text mining. Topics are represented by a short list of keywords\n",
    "(“topic representation”) and some simple metadata.\n",
    "\n",
    "Your task: for **each topic**, estimate:\n",
    "\n",
    "1) **Novelty** of the topic (how new or weakly institutionalized it is in the scientific/regulatory discourse)\n",
    "   - Scale: 1–5 (integer)\n",
    "     - 1 = Very established, mature topic; widely studied, well known.\n",
    "     - 2 = Established but still evolving; plenty of literature and prior regulatory attention.\n",
    "     - 3 = Moderately new; clearly present in the literature but not yet mainstream.\n",
    "     - 4 = New/weakly institutionalized; limited literature, niche or emerging.\n",
    "     - 5 = Very novel; highly niche, very sparse evidence, or clearly “upcoming” frontier.\n",
    "\n",
    "2) **Severity** of potential adverse outcomes if this topic turns into a manifest risk\n",
    "   (think about scale of harm to health, environment, economy, or society).\n",
    "   - Scale: 1–5 (integer)\n",
    "     - 1 = Negligible or very localized harm.\n",
    "     - 2 = Limited harm; mostly reversible, small populations or local ecosystems.\n",
    "     - 3 = Moderate harm; notable morbidity/mortality or environmental/economic impact.\n",
    "     - 4 = Severe harm; large-scale, long-lasting, or difficult to reverse.\n",
    "     - 5 = Catastrophic or systemic harm; wide populations or ecosystems, long-term damage.\n",
    "\n",
    "3) Propose a short, human-readable **topic label** (3–7 words) that an expert would find intuitive.\n",
    "   - Avoid generic labels like \"novel hazard topic\".\n",
    "   - Use concrete hazard/exposure/outcome language where possible.\n",
    "\n",
    "Important:\n",
    "- You do NOT have access to the underlying documents. You must infer from the topic representation + metadata.\n",
    "- If the topic is clearly about a well-known hazard (e.g. “salmonella outbreak, aflatoxin, PFOS, dioxin, asbestos”),\n",
    "  novelty is probably LOW (1–2), even if severity can be high.\n",
    "- If the topic looks niche, newly combined, or unclear, novelty can be HIGH (4–5).\n",
    "- Severity can be high even if novelty is low (e.g. classic but dangerous hazard).\n",
    "- When uncertain, choose the middle of the scale, but still commit to clear integers.\n",
    "\n",
    "Return your answer as valid compact JSON with the following keys:\n",
    "- \"novelty\" (int 1–5)\n",
    "- \"severity\" (int 1–5)\n",
    "- \"novelty_reason\" (string; 1–3 sentences)\n",
    "- \"severity_reason\" (string; 1–3 sentences)\n",
    "- \"topic_label\" (string; 3–7 words, intuitive label)\n",
    "\n",
    "DO NOT include any other top-level keys.\n",
    "DO NOT wrap the JSON in backticks.\n",
    "\n",
    "-------------------------\n",
    "TOPIC INFORMATION\n",
    "-------------------------\n",
    "Topic ID: {topic_id}\n",
    "Topic name: {topic_name}\n",
    "Count (approx. number of documents in topic): {count}\n",
    "Weak-signal score (if available): {weak_signal_score}\n",
    "\n",
    "Topic representation (keywords):\n",
    "{representation}\n",
    "\n",
    "(End of topic information)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bde84b0-75bf-4489-a01a-b2996717b448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3 — Interpreter with OpenAI + Gemini backend switch\n",
    "\n",
    "class LLMWeakSignalInterpreter:\n",
    "    \"\"\"\n",
    "    Uses either OpenAI or Gemini to score weak-signal topics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Select backend from LLM_PROVIDER\n",
    "        if LLM_PROVIDER.lower() == \"openai\":\n",
    "            self.llm = ChatOpenAI(\n",
    "                model=MODEL_NAME,\n",
    "                temperature=MODEL_TEMPERATURE,\n",
    "            )\n",
    "        elif LLM_PROVIDER.lower() == \"gemini\":\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=MODEL_NAME,\n",
    "                temperature=MODEL_TEMPERATURE,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown LLM provider: {LLM_PROVIDER}\")\n",
    "\n",
    "        # Prompt + output parser\n",
    "        self.prompt = ChatPromptTemplate.from_template(LLM_PROMPT_TEMPLATE)\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "\n",
    "    # -------- (rest of interpreter unchanged) --------\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_representation(rep: Any) -> str:\n",
    "        if isinstance(rep, (list, tuple)):\n",
    "            return \", \".join(map(str, rep))\n",
    "        if isinstance(rep, str) and rep.startswith(\"[\") and rep.endswith(\"]\"):\n",
    "            inner = rep[1:-1]\n",
    "            tokens = [\n",
    "                tok.strip().strip(\"'\\\"\")\n",
    "                for tok in inner.split(\",\")\n",
    "                if tok.strip()\n",
    "            ]\n",
    "            return \", \".join(tokens)\n",
    "        return str(rep)\n",
    "\n",
    "    @staticmethod\n",
    "    def _safe_get(row: pd.Series, key: str, default: Any = \"N/A\") -> Any:\n",
    "        return row[key] if key in row and pd.notna(row[key]) else default\n",
    "\n",
    "\n",
    "    def _call_llm_for_row(self, row: pd.Series, topic_id: int) -> Dict[str, Any]:\n",
    "        representation = self._normalize_representation(row[\"Representation\"])\n",
    "        topic_name = self._safe_get(row, \"Name\", f\"Topic_{topic_id}\")\n",
    "        count = self._safe_get(row, \"Count\", \"N/A\")\n",
    "\n",
    "        weak_signal_score = None\n",
    "        for candidate in [\"weak_signal_score\", \"score\", \"recency_jump_score\"]:\n",
    "            if candidate in row and pd.notna(row[candidate]):\n",
    "                weak_signal_score = row[candidate]\n",
    "                break\n",
    "\n",
    "        if isinstance(weak_signal_score, (int, float)):\n",
    "            weak_signal_score_str = f\"{weak_signal_score:.4f}\"\n",
    "        elif weak_signal_score is not None:\n",
    "            weak_signal_score_str = str(weak_signal_score)\n",
    "        else:\n",
    "            weak_signal_score_str = \"N/A\"\n",
    "\n",
    "        raw = self.chain.invoke(\n",
    "            {\n",
    "                \"topic_id\": topic_id,\n",
    "                \"topic_name\": topic_name,\n",
    "                \"count\": count,\n",
    "                \"weak_signal_score\": weak_signal_score_str,\n",
    "                \"representation\": representation,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "            novelty = int(data.get(\"novelty\", 3))\n",
    "            severity = int(data.get(\"severity\", 3))\n",
    "            novelty_reason = str(data.get(\"novelty_reason\", \"\")).strip()\n",
    "            severity_reason = str(data.get(\"severity_reason\", \"\")).strip()\n",
    "            topic_label = str(data.get(\"topic_label\", \"\")).strip()\n",
    "        except Exception:\n",
    "            novelty = severity = 3\n",
    "            novelty_reason = f\"Failed to parse JSON: {raw[:200]}\"\n",
    "            severity_reason = \"Failed to parse JSON.\"\n",
    "            topic_label = \"\"\n",
    "\n",
    "        novelty = max(1, min(5, novelty))\n",
    "        severity = max(1, min(5, severity))\n",
    "\n",
    "        return {\n",
    "            \"llm_novelty\": novelty,\n",
    "            \"llm_severity\": severity,\n",
    "            \"llm_topic_label\": topic_label,\n",
    "            \"llm_novelty_reason\": novelty_reason,\n",
    "            \"llm_severity_reason\": severity_reason,\n",
    "        }\n",
    "\n",
    "\n",
    "    def score_dataframe(self, df_weak: pd.DataFrame, show_progress=True):\n",
    "        df = df_weak.copy().reset_index(drop=True)\n",
    "        scores = []\n",
    "\n",
    "        iterator = range(len(df))\n",
    "        if show_progress:\n",
    "            iterator = tqdm(iterator, desc=\"Scoring weak signals…\")\n",
    "\n",
    "        for i in iterator:\n",
    "            scores.append(self._call_llm_for_row(df.iloc[i], topic_id=i))\n",
    "\n",
    "        return pd.concat([df, pd.DataFrame(scores)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1867f41-e910-4e1d-9842-38d959bbf4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weak-signal dataframe with shape: (10, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Count</th>\n",
       "      <th>score</th>\n",
       "      <th>weak_signal_score</th>\n",
       "      <th>Representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213_citrus_juice_marinated_sensory</td>\n",
       "      <td>11</td>\n",
       "      <td>0.401407</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>['citrus', 'juice', 'marinated', 'sensory', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181_sers_imprinted_qcm_spr</td>\n",
       "      <td>13</td>\n",
       "      <td>0.401350</td>\n",
       "      <td>0.610969</td>\n",
       "      <td>['sers', 'imprinted', 'qcm', 'spr', 'ecl', 'ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291_hets_alsub2subosub3sub_cuonps_nanosilver</td>\n",
       "      <td>8</td>\n",
       "      <td>0.273842</td>\n",
       "      <td>0.571281</td>\n",
       "      <td>['hets', 'alsub2subosub3sub', 'cuonps', 'nanos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>382_haploid_dh_colchicine_hmf</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200589</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>['haploid', 'dh', 'colchicine', 'hmf', 'doubli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347_dandelion_broth_uvbinduced_fermentation</td>\n",
       "      <td>7</td>\n",
       "      <td>0.217578</td>\n",
       "      <td>0.486752</td>\n",
       "      <td>['dandelion', 'broth', 'uvbinduced', 'fermenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  Count     score  \\\n",
       "0            213_citrus_juice_marinated_sensory     11  0.401407   \n",
       "1                    181_sers_imprinted_qcm_spr     13  0.401350   \n",
       "2  291_hets_alsub2subosub3sub_cuonps_nanosilver      8  0.273842   \n",
       "3                 382_haploid_dh_colchicine_hmf      6  0.200589   \n",
       "4   347_dandelion_broth_uvbinduced_fermentation      7  0.217578   \n",
       "\n",
       "   weak_signal_score                                     Representation  \n",
       "0           0.722222  ['citrus', 'juice', 'marinated', 'sensory', 'm...  \n",
       "1           0.610969  ['sers', 'imprinted', 'qcm', 'spr', 'ecl', 'ca...  \n",
       "2           0.571281  ['hets', 'alsub2subosub3sub', 'cuonps', 'nanos...  \n",
       "3           0.500009  ['haploid', 'dh', 'colchicine', 'hmf', 'doubli...  \n",
       "4           0.486752  ['dandelion', 'broth', 'uvbinduced', 'fermenta...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: Load weak-signal CSV\n",
    "\n",
    "df_weak = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded weak-signal dataframe with shape:\", df_weak.shape)\n",
    "display(df_weak.head())\n",
    "\n",
    "# Optional: check that Representation exists\n",
    "if \"Representation\" not in df_weak.columns:\n",
    "    raise ValueError(\"The CSV must contain a 'Representation' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757e76b7-f68e-43d9-8f81-284caea96f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring weak signals…: 100%|██████████| 10/10 [01:55<00:00, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored dataframe shape: (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Count</th>\n",
       "      <th>score</th>\n",
       "      <th>weak_signal_score</th>\n",
       "      <th>Representation</th>\n",
       "      <th>llm_novelty</th>\n",
       "      <th>llm_severity</th>\n",
       "      <th>llm_topic_label</th>\n",
       "      <th>llm_novelty_reason</th>\n",
       "      <th>llm_severity_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213_citrus_juice_marinated_sensory</td>\n",
       "      <td>11</td>\n",
       "      <td>0.401407</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>['citrus', 'juice', 'marinated', 'sensory', 'm...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Citrus juice meat marinade sensory</td>\n",
       "      <td>Research on food marination and sensory effect...</td>\n",
       "      <td>Primary impacts are on sensory quality and con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181_sers_imprinted_qcm_spr</td>\n",
       "      <td>13</td>\n",
       "      <td>0.401350</td>\n",
       "      <td>0.610969</td>\n",
       "      <td>['sers', 'imprinted', 'qcm', 'spr', 'ecl', 'ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Surface and aptamer-based biosensors</td>\n",
       "      <td>The keywords describe well-established analyti...</td>\n",
       "      <td>This is primarily a detection/monitoring techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291_hets_alsub2subosub3sub_cuonps_nanosilver</td>\n",
       "      <td>8</td>\n",
       "      <td>0.273842</td>\n",
       "      <td>0.571281</td>\n",
       "      <td>['hets', 'alsub2subosub3sub', 'cuonps', 'nanos...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Nanoparticle-induced NETs formation</td>\n",
       "      <td>The topic combines specific engineered nanopar...</td>\n",
       "      <td>If nanoparticle-induced neutrophil extracellul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>382_haploid_dh_colchicine_hmf</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200589</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>['haploid', 'dh', 'colchicine', 'hmf', 'doubli...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Colchicine-induced doubled haploids</td>\n",
       "      <td>Doubled-haploid production and colchicine-indu...</td>\n",
       "      <td>Colchicine is a toxic mitotic inhibitor so occ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347_dandelion_broth_uvbinduced_fermentation</td>\n",
       "      <td>7</td>\n",
       "      <td>0.217578</td>\n",
       "      <td>0.486752</td>\n",
       "      <td>['dandelion', 'broth', 'uvbinduced', 'fermenta...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>UVB-induced dandelion skin fermentation</td>\n",
       "      <td>The combination of dandelion extracts, UVB-ind...</td>\n",
       "      <td>Potential harms are primarily topical (irritat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  Count     score  \\\n",
       "0            213_citrus_juice_marinated_sensory     11  0.401407   \n",
       "1                    181_sers_imprinted_qcm_spr     13  0.401350   \n",
       "2  291_hets_alsub2subosub3sub_cuonps_nanosilver      8  0.273842   \n",
       "3                 382_haploid_dh_colchicine_hmf      6  0.200589   \n",
       "4   347_dandelion_broth_uvbinduced_fermentation      7  0.217578   \n",
       "\n",
       "   weak_signal_score                                     Representation  \\\n",
       "0           0.722222  ['citrus', 'juice', 'marinated', 'sensory', 'm...   \n",
       "1           0.610969  ['sers', 'imprinted', 'qcm', 'spr', 'ecl', 'ca...   \n",
       "2           0.571281  ['hets', 'alsub2subosub3sub', 'cuonps', 'nanos...   \n",
       "3           0.500009  ['haploid', 'dh', 'colchicine', 'hmf', 'doubli...   \n",
       "4           0.486752  ['dandelion', 'broth', 'uvbinduced', 'fermenta...   \n",
       "\n",
       "   llm_novelty  llm_severity                          llm_topic_label  \\\n",
       "0            2             1       Citrus juice meat marinade sensory   \n",
       "1            3             2     Surface and aptamer-based biosensors   \n",
       "2            4             3      Nanoparticle-induced NETs formation   \n",
       "3            2             2      Colchicine-induced doubled haploids   \n",
       "4            4             2  UVB-induced dandelion skin fermentation   \n",
       "\n",
       "                                  llm_novelty_reason  \\\n",
       "0  Research on food marination and sensory effect...   \n",
       "1  The keywords describe well-established analyti...   \n",
       "2  The topic combines specific engineered nanopar...   \n",
       "3  Doubled-haploid production and colchicine-indu...   \n",
       "4  The combination of dandelion extracts, UVB-ind...   \n",
       "\n",
       "                                 llm_severity_reason  \n",
       "0  Primary impacts are on sensory quality and con...  \n",
       "1  This is primarily a detection/monitoring techn...  \n",
       "2  If nanoparticle-induced neutrophil extracellul...  \n",
       "3  Colchicine is a toxic mitotic inhibitor so occ...  \n",
       "4  Potential harms are primarily topical (irritat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LLM-scored weak signals to: /home/jupyter/WSM/data/holifood_weak_singals_scored.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run LLM scoring & save results, then print\n",
    "\n",
    "# Uses MODEL_NAME and MODEL_TEMPERATURE from Cell 1 via the class\n",
    "interpreter = LLMWeakSignalInterpreter()\n",
    "\n",
    "df_scored = interpreter.score_dataframe(df_weak, show_progress=True)\n",
    "\n",
    "print(\"Scored dataframe shape:\", df_scored.shape)\n",
    "\n",
    "# Quick preview\n",
    "display(df_scored.head())\n",
    "\n",
    "# Save to CSV\n",
    "df_scored.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved LLM-scored weak signals to:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49ea25-27f6-41bd-97a4-1f324bc8a050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
